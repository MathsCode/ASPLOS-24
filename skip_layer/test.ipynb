{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_name = 'Llama-7B'\n",
    "train_data = torch.load('/home/xujiaming/xujiaming/research/ASPLOS-24/results/'+model_name+'_feature.pt')\n",
    "train_label = torch.load('/home/xujiaming/xujiaming/research/ASPLOS-24/results/'+model_name+'_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/home/xujiaming/xujiaming/research/ASPLOS-24/results/model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3903, 0.7349, 0.9442,  ..., 0.2022, 0.5751, 0.8548]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,4096+8).to(model.fc1.weight.device)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0065]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = torch.load('/home/xujiaming/xujiaming/research/ASPLOS-24/results/train_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 1, 1, 1], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/xujiaming/anaconda3/envs/spec_de/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-26 22:28:37,906] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 15.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from eagle.model.ea_model import EaModel\n",
    "from fastchat.model import get_conversation_template\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from typing import Optional\n",
    "import json\n",
    "import time \n",
    "\n",
    "model = EaModel.from_pretrained(\n",
    "    base_model_path='/share/datasets/public_models/Llama-2-7b-chat-hf',\n",
    "    ea_model_path=\"/home/xujiaming/xujiaming/datasets/LLM_models/EAGLE-llama2-chat-7B\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    "    # is_offload = False,\n",
    "    # skip_model = \"/home/xujiaming/xujiaming/research/ASPLOS-24/skip_layer/model.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4096])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.lm_head.weight[[[[1,23,3222,3432]]]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top=torch.topk(a, 3, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([11, 10,  9]),\n",
       "indices=tensor([11, 10,  9]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for x in range(18,32):\n",
    "    max_acc = 0\n",
    "    min_err = 100000\n",
    "    threshold = 19.75\n",
    "    while threshold < 30:\n",
    "        acc = 0\n",
    "        err = 0\n",
    "        for i in range(x,train_data.shape[0],32):\n",
    "            max_prob = torch.max(train_data[i],dim=-1).values\n",
    "            if(max_prob > threshold and train_label[i] == 1):\n",
    "                acc += 1\n",
    "            if max_prob > threshold and train_label[i] == 0:\n",
    "                err += 1\n",
    "        tot = torch.sum(train_label[x:-1:32])\n",
    "        acc_ratio= acc / tot\n",
    "        # if acc > max_acc:\n",
    "        #     max_acc = acc\n",
    "        #     threshold_set_err[x] = threshold\n",
    "        if err < min_err:\n",
    "            min_err = err\n",
    "            threshold_set_err[x] = threshold\n",
    "        threshold += 0.25\n",
    "        \n",
    "    print(x,threshold_set_err[x],acc_ratio,int(acc),'/',int(tot),int(err),'/',int(tot))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_ratio = 2\n",
    "threshold = 6.5\n",
    "# for x in range(32):\n",
    "x = 0\n",
    "acc = 0\n",
    "err = 0\n",
    "for i in range(x,train_data.shape[0],32):\n",
    "    result_descend = train_data[i].sort(descending=True).values\n",
    "    result_descend_soft = torch.nn.functional.softmax(result_descend,dim=-1)\n",
    "    top_logits = result_descend[0]\n",
    "    second_logits = result_descend[1]\n",
    "    top_prob = result_descend_soft[0]\n",
    "    second_prob = result_descend_soft[1]\n",
    "    if(top_prob / second_prob > threshold_ratio and top_logits / second_logits > threshold_ratio and top_logits > threshold):\n",
    "        if train_label[i] == 1:\n",
    "            acc += 1\n",
    "        else:\n",
    "            print(result_descend,result_descend_soft,train_label[i])\n",
    "            err += 1\n",
    "tot = torch.sum(train_label[x:-1:32])\n",
    "acc_ratio = acc / tot\n",
    "print(x,acc_ratio,int(acc),'/',int(tot),int(err),'/',int(tot),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "a = a.sort(descending=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2826536/2430103232.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.nn.functional.softmax(a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6439, 0.2369, 0.0871, 0.0321])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((1,100))\n",
    "b = torch.ones((4,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1,2,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec_de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
