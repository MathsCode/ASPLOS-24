[2024-10-14 15:04:20,935] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Output to mt_bench/ess-llama-2-chat-70b-fp16-temperature-0.0.jsonl
Check model training state: False
CUDA VISIBLE DEVICES: 7
Warmup done
0.010616056678831115
0.13080811500549316
0.008315339031447452
0.019316809517996653
0.009159484529882913
0.021816333134969074
0.00809137644934747
0.019140754427228655
0.011240578466846098
0.018701417105538503
0.010580589604932208
0.01884286744253976
0.010640022387871375
0.018091746738978794
0.01212065111507069
0.010069379806518555
0.008322305046021938
0.018860340118408203
0.009136949777603149
0.019717863627842495
0.0106739058918014
0.06447505950927734
0.013359227488117834
0.04659128189086914
0.009398596298291487
0.018554619380405972
0.008885004941154928
0.03220927715301514
0.01067025741834319
0.021531144777933758
0.00905278667074735
0.032621681690216064
0.008620726543924083
0.019031388419015065
0.013447654781056874
0.013166846651019472
0.011067653047865715
0.008620186855918482
0.010996402740478516
0.06647801399230957
0.009633850118967408
0.010590658738062931
0.010129173596700033
0.010399678018358019
0.009053640415013763
0.009929653576442174
0.008627173775120785
0.008772306227951908
0.008140222022407934
0.018261739185878208
0.008237283076009443
0.007348105714127824
0.008672734965448793
0.007496283948421478
0.009466943286714099
0.007735537958669139
0.009153254080138751
0.009431588344084911
0.009455645165475859
0.06549656391143799
0.007794380187988281
0.06360149383544922
0.006557598279390721
0.00909412247794015
0.007890200414577452
0.06651020050048828
0.0072781492300070675
0.06511151790618896
0.007818317000484054
0.03208571672439575
0.010156010358761519
0.007653722637578061
0.009426267817616463
0.009429020847348
0.009415344525409002
0.007421709086797009
0.00825909502017572
0.011107769879427824
0.007090283930301667
0.00863684102108604
0.009129424039491884
0.018650429589407786
0.006113458700217162
0.018287726811000278
0.00884322097018304
0.018686226436070034
0.010067953152602978
0.061333258946736656
0.008421724576216478
0.04300673802693685
0.007932128487052499
0.009026586235343637
0.007237576699072076
0.021616101264953613
0.008370567285097563
0.06612265110015869
0.008146139291616587
0.008814134905415197
0.00779113045926224
0.018534490040370395
0.008295179352046936
0.018712009702410017
0.007682997503398377
0.018448489052908763
0.029890680313110353
0.030672168731689452
0.008637332296990728
0.019887072699410573
0.00747910114603305
0.021458109219868977
0.02182455857594808
0.0191587039402553
0.008246653516527633
0.02230525016784668
0.021561384201049805
0.024750153223673504
0.0077203030281878535
0.018552541732788086
0.018538100378853933
0.029123210906982423
0.008957043346796652
0.018132993153163364
0.009939935109386705
0.00918131435618681
0.009462137331907776
0.018566233771187917
0.009245702462602956
0.019492183412824358
0.009102732823367864
0.025795698165893555
0.008335430189449355
0.018273353576660156
0.007673454085154513
0.026349210739135744
0.008521775021055951
0.018509115491594588
0.0076371289761130385
0.01887358937944685
0.010403408454014705
0.04318753878275553
0.008562924796969046
0.04265721638997396
0.00944101392990884
0.012912640204796424
0.011192505387054092
0.018424204417637417
0.008640646443936069
0.018888882228306363
0.009064479974599984
0.021762410799662273
0.01106115367061408
0.018165315900530134
0.008712600641213502
0.03521909713745117
0.008929678832241928
0.01824287005833217
0.011436589928560479
0.021735469500223797
0.011772748561220875
0.01876967293875558
