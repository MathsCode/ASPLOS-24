[2024-10-14 13:16:10,658] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Output to mt_bench/ess-llama-2-chat-70b-fp16-temperature-0.0.jsonl
Check model training state: False
CUDA VISIBLE DEVICES: 1
Warmup done
0.009339637405867733
0.007867298572259917
0.007367034912109375
0.0073517156369758375
0.007873385040848344
0.009305245840727394
0.00778048406771528
0.007392298754523782
0.010137067522321429
0.00874033629656788
0.00837969183921814
0.011037236301057752
0.008609330911430523
0.0116271271425135
0.009475004565608394
0.009569126367568969
0.007122956647836103
0.008727033933003744
0.00779268305788758
0.007022912303606669
0.010401256589869104
0.010389183101982906
0.010945419256832437
0.0072044796413845485
0.007942546603163373
0.00659555084300491
0.00791806070243611
0.008055426701005683
0.009435485649812706
0.006836262391638879
0.008015649659293038
0.007088501249725495
0.006970413927902043
0.007499805006008704
0.010683023246230593
0.010055886053865816
0.00915694421575975
0.009483144396827334
0.008322643541201517
0.008728410683426202
0.009227183427703515
0.0075628625022040475
0.009789711044680688
0.0071278290460573745
0.007029831409454346
0.00784505738152398
0.009028804411581897
0.007874131202697754
0.007697509474543683
0.007883110354023596
0.007487252980721097
0.008045336178370884
0.0072516918182373045
0.007121658602426219
0.007520261018172554
0.0064431253601523
0.00767993568477774
0.006963575486656573
0.009093091709801576
0.0082840515296055
0.008035237394918607
0.007374094592200385
0.007250953528840663
0.006935776404614719
0.008701088370346442
0.0063280544497750025
0.006741967797279358
0.0060416705599438385
0.00712433048323089
0.006983449158159275
0.008041706491023936
0.00872888842832695
0.008161385383831678
0.007556962031944126
0.007887187685285296
0.007618223537098278
0.0069953436827539794
0.00739995090440772
0.00798393735949625
0.006493179421675832
0.008290552830958104
0.006367574764203422
0.007518337918566419
0.00579088705557364
0.007237863437882785
0.006269531175639429
0.006318543958175711
0.006585472532846396
0.00753690931532118
0.006844625781904831
0.007962910618100847
0.006558280450561118
0.0069828884309109255
0.00687746497673717
0.007139099286367519
0.006151669273965607
0.007552120420667861
0.00705789391105697
0.00574437217040209
0.006264423992240405
0.006307392208664505
0.005395456555297279
0.0062087726111363884
0.006441246668497721
0.006406002940393943
0.006037872664782466
0.009083625248500279
0.005377406733376639
0.006627999519815251
0.008241625780558717
0.0068982634881530145
0.007281414298124091
0.008113976182608769
0.009322474984561695
0.007139465526530617
0.0055053209091399935
0.008905539953761164
0.01036217579474816
0.006020844850123796
0.00567018893337989
0.007394993177024267
0.006834021355341939
0.00800623838129961
0.008410502702761918
0.008284895490891862
0.007852349763714387
0.00901270664490021
0.009062144335578469
0.00849911075854591
0.006636846940029542
0.007202261640119922
0.008814179807677305
0.008311951674475073
0.007482247545539988
0.007449110581396151
0.006863336729127157
0.007622944317196048
0.007760539137083909
0.007510389921800146
0.007264838116443181
0.007830174113342404
0.009629073431152583
0.008433479361417816
0.010041671168523204
0.00992054522616192
0.007933589734919803
0.00849060432330982
0.0065285025490047595
0.00812212104502792
0.00676587258795356
0.00788789944057047
0.008258583944595277
0.007389840916690663
0.007089364898297213
0.008078227372005068
0.008267244012439298
0.008286413758300071
0.007973453713199807
0.009272344819792024
0.008827300564355088
